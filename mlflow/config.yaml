# routes:
#   - name: ollama
#     route_type: llm/v1/chat
#     model:
#       provider: openai
#       name: llama3
#       config:
#         openai_api_key: ""
#         # https://ollama.com/blog/openai-compatibility
#         openai_api_base: http://172.17.0.1:11434/v1
