# https://github.com/adamksiezyk/data-science-workbench/blob/mlflow-local-llm/docker-compose.yml
version: '3.8'
services:
  app:
    # image: 
    build: ./llm_server
    ports:
      - 8000:8000
    volumes:
      - ./llm_server:/app/
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    restart: always
    environment:
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}
      - OLLAMA_URI=http://host.docker.internal:11434
      - OLLAMA_MODEL=Meta-Llama-3-8B-Instruct.Q8_0.gguf
    depends_on:
      - mlflow-server
    networks:
      - ollama-docker
  mlflow-server:
    image: ghcr.io/mlflow/mlflow
    command: 'mlflow server --host 0.0.0.0 --port ${MLFLOW_SERVER_PORT} --backend-store-uri sqlite:////app/db.sqlite --gunicorn-opts "--timeout=120"'
    ports:
      - ${MLFLOW_SERVER_PORT}:${MLFLOW_SERVER_PORT}
    volumes:
      - ./data/mlflow:/app
    restart: always
    networks:
      - ollama-docker
  

networks:
  ollama-docker:
    external: false