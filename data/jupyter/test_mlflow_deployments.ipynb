{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84254f84-dc14-4b9d-926c-71e9f66cadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q mlflow[genai]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd552dd0-35e0-49d3-a7b7-80fddd4aadb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_config.py:334: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import mlflow.deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19317074-5e5b-4b07-b99b-f34bd85a3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.deployments.get_deploy_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041e7d46-5b74-4345-82f0-6e4c7284d221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Endpoint(name='ollama', endpoint_type='llm/v1/chat', model=RouteModelInfo(name='llama3', provider='openai'), endpoint_url='http://mlflow-deployments:5000/gateway/ollama/invocations', limit=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba00daf-3e62-4076-a226-4b2c37336b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-785', 'object': 'chat.completion', 'created': 1714625380, 'model': 'llama3', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"A complex individual, indeed!\\n\\nConsidering your traits: bravery, hard-work, wisdom, and a hint of cunning (backstabbing), I would say you're most likely to be sorted into... Slytherin!\\n\\nSlytherin values ambition, cleverness, and resourcefulness, which aligns with your wise and hard-working nature. While bravery is not typically associated with Slytherin, your willingness to take calculated risks suggests that you might have a bit of the bold and daring spirit within you.\\n\\nHowever, be warned: your backstabbing tendencies might raise some eyebrows among the other Slytherins, who tend to prize loyalty and cunning over outright deception. Nonetheless, I think you'd find a certain... appreciation for the more... creative aspects of Slytherin's values.\\n\\nSo, there you have it! You're a Slytherin at heart!\\n\\nNow, if you'll excuse me, I need to get back to sorting the next student...\"}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 0, 'completion_tokens': 193, 'total_tokens': 193}}\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    'messages': [\n",
    "        {\"role\": \"system\", \"content\": \"You are the sorting hat from harry potter.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I am brave, hard-working, wise, and backstabbing.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Which harry potter house am I most likely to belong to?\"},\n",
    "    ],\n",
    "    'temperature': 0.2,\n",
    "    'max_tokens': 1024,\n",
    "}\n",
    "response = client.predict(endpoint=\"ollama\", inputs=query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900527e-8dc6-43d5-979a-90f1e9da0a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
